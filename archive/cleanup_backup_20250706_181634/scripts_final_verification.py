#!/usr/bin/env python3
"""
Final verification script to confirm codebase is ready for commit.
"""

import os
from pathlib import Path
import json

def final_verification():
    """Perform final verification checks"""
    print("ğŸ” FINAL VERIFICATION CHECKLIST")
    print("=" * 80)
    
    checks = {
        "core_structure": False,
        "no_temp_files": False,
        "bot_data_intact": False,
        "archive_organized": False,
        "documentation_complete": False
    }
    
    # Check 1: Core structure intact
    print("\nâœ… CHECKING CORE STRUCTURE")
    print("-" * 40)
    essential_dirs = ["agentic", "scripts", "tests", "docs", "data"]
    essential_files = ["main.py", "requirements.txt", ".env", "readme.md"]
    
    all_dirs_exist = all(Path(d).exists() for d in essential_dirs)
    all_files_exist = all(Path(f).exists() for f in essential_files)
    
    if all_dirs_exist and all_files_exist:
        checks["core_structure"] = True
        print("   âœ… All essential directories and files present")
        
        # Count Python files
        agentic_py = len(list(Path("agentic").rglob("*.py")))
        scripts_py = len(list(Path("scripts").rglob("*.py")))
        tests_py = len(list(Path("tests").rglob("*.py")))
        print(f"   ğŸ“Š Python files: agentic/{agentic_py}, scripts/{scripts_py}, tests/{tests_py}")
    else:
        print("   âŒ Missing essential directories or files")
    
    # Check 2: No temporary files in main directories
    print("\nâœ… CHECKING FOR TEMPORARY FILES")
    print("-" * 40)
    
    temp_patterns = ["*backup*", "*temp*", "*debug*", "*test_*", "*tmp*"]
    temp_files_found = []
    
    for pattern in temp_patterns:
        temp_files_found.extend(list(Path(".").glob(pattern)))
        temp_files_found.extend(list(Path("data").glob(pattern)))
        temp_files_found.extend(list(Path("scripts").glob(pattern)))
    
    # Filter out archive directory
    temp_files_found = [f for f in temp_files_found if not str(f).startswith("archive")]
    
    if not temp_files_found:
        checks["no_temp_files"] = True
        print("   âœ… No temporary files in main directories")
    else:
        print(f"   âš ï¸ Found {len(temp_files_found)} potential temporary files:")
        for f in temp_files_found[:5]:  # Show first 5
            print(f"      - {f}")
    
    # Check 3: Bot data intact
    print("\nâœ… CHECKING BOT DATA INTEGRITY")
    print("-" * 40)
    
    chromadb_exists = Path("data/chromadb").exists()
    messages_exist = Path("data/fetched_messages").exists()
    config_exists = Path("data/bot_config.json").exists()
    
    if chromadb_exists and messages_exist and config_exists:
        checks["bot_data_intact"] = True
        
        # Count data files
        chromadb_files = len(list(Path("data/chromadb").rglob("*")))
        message_files = len(list(Path("data/fetched_messages").glob("*.json")))
        
        print("   âœ… All bot data directories present")
        print(f"   ğŸ“Š ChromaDB files: {chromadb_files}")
        print(f"   ğŸ“Š Message files: {message_files}")
    else:
        print("   âŒ Missing bot data directories")
    
    # Check 4: Archive organized
    print("\nâœ… CHECKING ARCHIVE ORGANIZATION")
    print("-" * 40)
    
    archive_dir = Path("archive")
    if archive_dir.exists():
        archive_subdirs = [d for d in archive_dir.iterdir() if d.is_dir()]
        archive_files = len(list(archive_dir.rglob("*")))
        
        if len(archive_subdirs) >= 6:  # Should have multiple cleanup phases
            checks["archive_organized"] = True
            print(f"   âœ… Archive organized with {len(archive_subdirs)} categories")
            print(f"   ğŸ“¦ Total archived items: {archive_files}")
            
            for subdir in sorted(archive_subdirs):
                items = len(list(subdir.rglob("*")))
                print(f"      - {subdir.name}: {items} items")
        else:
            print(f"   âš ï¸ Archive exists but may be incomplete ({len(archive_subdirs)} categories)")
    else:
        print("   âŒ Archive directory not found")
    
    # Check 5: Documentation complete
    print("\nâœ… CHECKING DOCUMENTATION")
    print("-" * 40)
    
    doc_files = [
        "readme.md",
        "PROJECT_STRUCTURE.md", 
        "CLEANUP_COMPLETE.md",
        "docs/QUICKSTART.md",
        "docs/DEPLOYMENT.md"
    ]
    
    existing_docs = [doc for doc in doc_files if Path(doc).exists()]
    
    if len(existing_docs) >= 4:
        checks["documentation_complete"] = True
        print(f"   âœ… Documentation complete ({len(existing_docs)}/{len(doc_files)} files)")
        for doc in existing_docs:
            size = Path(doc).stat().st_size
            print(f"      - {doc}: {size:,} bytes")
    else:
        print(f"   âš ï¸ Documentation incomplete ({len(existing_docs)}/{len(doc_files)} files)")
    
    # Final summary
    print(f"\nğŸ¯ FINAL VERIFICATION SUMMARY")
    print("=" * 80)
    
    passed_checks = sum(checks.values())
    total_checks = len(checks)
    
    print(f"ğŸ“Š VERIFICATION RESULTS: {passed_checks}/{total_checks} checks passed")
    print()
    
    for check_name, passed in checks.items():
        status = "âœ… PASS" if passed else "âŒ FAIL"
        print(f"   {status} {check_name.replace('_', ' ').title()}")
    
    if passed_checks == total_checks:
        print(f"\nğŸ‰ ALL CHECKS PASSED!")
        print(f"ğŸš€ Codebase is ready for commit!")
        return True
    else:
        print(f"\nâš ï¸ {total_checks - passed_checks} checks failed")
        print(f"ğŸ“‹ Please review failed items before committing")
        return False

if __name__ == "__main__":
    success = final_verification()
    exit(0 if success else 1)
